library(glmnet)
library(Hmisc)
library(rms)
library(caret)
library(ipflasso)
library(dplyr)
rm(list=ls())
### generate the mock data  ------------------
f=function(x){
a=0.5+0.2*x^2-x+0.4*log(abs(x+1)+2)+sin(x); return(a)}
expit<-function(x){ exp(x)/(1 + exp(x))}
N=1000
x1.full=x1 <- rnorm(N)
x2.full=x2 <- f(x1)  # we will assume this to be the outcome we want to predict
x3 <- runif(N)
m <- 100
p.miss=expit(-1.5-0.5*x1.full)
miss.x2 = rbinom(N, 1,  prob = p.miss)
x2[miss.x2==1]<-NA ### missing outcomes
x4<-rbinom(N,1,0.3)
x1[which(x1 %in% sample(x1, m))]<-NA ### missing predictors
x3[which(x3 %in% sample(x3, m))]<-NA ### missing predictors
plot(x1.full, x2.full)
data.original=data.frame(x1, x2, x3,x4)
### perform multiple imputations, assuming splines for x1 and x3 -----
n.impute=5
a <- aregImpute(I(x2)~x1+x3+I(x4), n.impute=n.impute, nk=6, match='closest')
# get imputed datasets
imputed=list()
for (i in 1:n.impute){
imputed[[i]] <- impute.transcan(a, imputation=i, data=data.original, list.out=TRUE,
pr=FALSE, check=FALSE)}
plot(imputed[[3]]$x2[1:m],f(x1)[1:m]) #### this is the imputed versus true outcomes
# fit a model with splines using maximum likelihood
#fmp <- fit.mult.impute(I(x2)~rcs(x1,6)+rcs(x3, 6)+x4, xtrans = a, data=data.original, fitter=ols)
#plot(x2.full, predict(fmp, data.original))
#summary(lm( x2.full~predict(fmp, data.original)))
# split in 10 folds and fit ridge in each fold
k.folds=10
lambdas <- 10^seq(3, -8, by = -0.3)
predictions.ridge=rep(NA,N)
folds <- createFolds(c(1:N), k = k.folds, list = TRUE, returnTrain = FALSE)
imputed.cv<-list()
nreps=3
fold.names<-names(folds)
f=1
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)
})
res = do.call(rbind,res)
}
res
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
g1=glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
})
}
f=1
i=1
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)
res = do.call(rbind,res)
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
}
coefficients.ridge=as.matrix(coefficients(cvfit[[1]]))
for (i in 2:n.impute){coefficients.ridge=cbind(coefficients.ridge,
as.matrix(coefficients(cvfit[[i]]))
)}
as.matrix(coefficients(cvfit[[1]]))
coefficients.ridge1=rowMeans(coefficients.ridge) ### coefficients for x4 and x3 are ~0
X=as.matrix(data_glmnet[,-1])
predictions.ridge[out.fold]=coefficients.ridge1[1]+X[out.fold,] %*% coefficients.ridge1[2:length(coefficients.ridge1)]
plot(x2.full,predictions.ridge)  ### these are the out of sample predictions
summary(lm(x2.full~predictions.ridge))
# split in 10 folds and fit ridge in each fold
k.folds=10
lambdas <- 10^seq(3, -8, by = -0.3)
predictions.ridge=rep(NA,N)
folds <- createFolds(c(1:N), k = k.folds, list = TRUE, returnTrain = FALSE)
imputed.cv<-list()
nreps=3
fold.names<-names(folds)
for (f in 1:k.folds){
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
}
coefficients.ridge=as.matrix(coefficients(cvfit[[1]]))
for (i in 2:n.impute){coefficients.ridge=cbind(coefficients.ridge,
as.matrix(coefficients(cvfit[[i]]))
)}
coefficients.ridge1=rowMeans(coefficients.ridge) ### coefficients for x4 and x3 are ~0
X=as.matrix(data_glmnet[,-1])
predictions.ridge[out.fold]=coefficients.ridge1[1]+X[out.fold,] %*% coefficients.ridge1[2:length(coefficients.ridge1)]
}
plot(x2.full,predictions.ridge)  ### these are the out of sample predictions
summary(lm(x2.full~predictions.ridge))
mean((x2.full-predictions.ridge)^2)
mean((x2.full-predictions.ridge)^2) ###MSE
# split in 10 folds and fit ridge in each fold
k.folds=10
lambdas <- 10^seq(3, -8, by = -0.3)
predictions.ridge=rep(NA,N)
folds <- createFolds(c(1:N), k = k.folds, list = TRUE, returnTrain = FALSE)
imputed.cv<-list()
nreps=3
fold.names<-names(folds)
for (f in 1:k.folds){
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda_1se)
}
coefficients.ridge=as.matrix(coefficients(cvfit[[1]]))
for (i in 2:n.impute){coefficients.ridge=cbind(coefficients.ridge,
as.matrix(coefficients(cvfit[[i]]))
)}
coefficients.ridge1=rowMeans(coefficients.ridge) ### coefficients for x4 and x3 are ~0
X=as.matrix(data_glmnet[,-1])
predictions.ridge[out.fold]=coefficients.ridge1[1]+X[out.fold,] %*% coefficients.ridge1[2:length(coefficients.ridge1)]
}
plot(x2.full,predictions.ridge)  ### these are the out of sample predictions
summary(lm(x2.full~predictions.ridge))
mean((x2.full-predictions.ridge)^2) ###MSE
rm(list=ls())
### generate the mock data  ------------------
f=function(x){
a=0.5+0.2*x^2-x+0.4*log(abs(x+1)+2)+sin(x); return(a)}
expit<-function(x){ exp(x)/(1 + exp(x))}
N=1000
x1.full=x1 <- rnorm(N)
x2.full=x2 <- f(x1)  # we will assume this to be the outcome we want to predict
x3 <- runif(N)
m <- 100
p.miss=expit(-1.5-0.5*x1.full)
miss.x2 = rbinom(N, 1,  prob = p.miss)
x2[miss.x2==1]<-NA ### missing outcomes
x4<-rbinom(N,1,0.3)
x1[which(x1 %in% sample(x1, m))]<-NA ### missing predictors
x3[which(x3 %in% sample(x3, m))]<-NA ### missing predictors
plot(x1.full, x2.full)
data.original=data.frame(x1, x2, x3,x4)
### perform multiple imputations, assuming splines for x1 and x3 -----
n.impute=5
a <- aregImpute(I(x2)~x1+x3+I(x4), n.impute=n.impute, nk=6, match='closest')
# get imputed datasets
imputed=list()
for (i in 1:n.impute){
imputed[[i]] <- impute.transcan(a, imputation=i, data=data.original, list.out=TRUE,
pr=FALSE, check=FALSE)}
plot(imputed[[3]]$x2[1:m],f(x1)[1:m]) #### this is the imputed versus true outcomes
# fit a model with splines using maximum likelihood
#fmp <- fit.mult.impute(I(x2)~rcs(x1,6)+rcs(x3, 6)+x4, xtrans = a, data=data.original, fitter=ols)
#plot(x2.full, predict(fmp, data.original))
#summary(lm( x2.full~predict(fmp, data.original)))
# split in 10 folds and fit ridge in each fold
k.folds=10
lambdas <- 10^seq(3, -8, by = -0.3)
predictions.ridge=rep(NA,N)
folds <- createFolds(c(1:N), k = k.folds, list = TRUE, returnTrain = FALSE)
imputed.cv<-list()
nreps=3
fold.names<-names(folds)
for (f in 1:k.folds){
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda_1se)
}
coefficients.ridge=as.matrix(coefficients(cvfit[[1]]))
for (i in 2:n.impute){coefficients.ridge=cbind(coefficients.ridge,
as.matrix(coefficients(cvfit[[i]]))
)}
coefficients.ridge1=rowMeans(coefficients.ridge) ### coefficients for x4 and x3 are ~0
X=as.matrix(data_glmnet[,-1])
predictions.ridge[out.fold]=coefficients.ridge1[1]+X[out.fold,] %*% coefficients.ridge1[2:length(coefficients.ridge1)]
}
plot(x2.full,predictions.ridge)  ### these are the out of sample predictions
summary(lm(x2.full~predictions.ridge))
mean((x2.full-predictions.ridge)^2) ###MSE
# split in 10 folds and fit ridge in each fold
k.folds=10
lambdas <- 10^seq(3, -8, by = -0.3)
predictions.ridge=rep(NA,N)
folds <- createFolds(c(1:N), k = k.folds, list = TRUE, returnTrain = FALSE)
imputed.cv<-list()
nreps=3
fold.names<-names(folds)
for (f in 1:k.folds){
out.fold<- eval(parse(text=paste("folds", "$", fold.names[f], sep="")))
cvfit=list()
for( i in 1:n.impute){
splined.x1 <- bs(imputed[[i]]$x1, df = 6) #rcspline.eval(imputed[[i]]$x1, nk = 6) #
splined.x3 <- bs(imputed[[i]]$x3, df = 6) #rcspline.eval(imputed[[i]]$x3, nk = 6)#
dfSplined.x1 <- as.data.frame(splined.x1)
dfSplined.x3 <- as.data.frame(splined.x3)
imp<- imputed[[i]]
imp$x1 <- NULL
imp$x3 <- NULL
imp <- cbind(imp$x2,imp$x4, dfSplined.x1, dfSplined.x3)
colnames(imp)=c("x2", "x4", as.character(1:(length(colnames(imp))-2)))
data_glmnet <- model.matrix(x2 ~.,data = imp)
data_glmnet <- data_glmnet[,-1]
data_glmnet <- cbind(x2 = x2, data_glmnet = data_glmnet)
data_glmnet1<-data_glmnet[-out.fold,]
data_glmnet1=data_glmnet1[complete.cases(data_glmnet1),]
X1=as.matrix(data_glmnet1[,-1])
Y1=data_glmnet1[,1]
#cvfit[[i]] <- cv.glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambdas)
res = lapply(1:nreps,function(i){
fit = cv.glmnet(X1,Y1,family = "gaussian",alpha=0,
lambda = lambdas, nfolds=10)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)})
res = do.call(rbind,res)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
idx = which.min(summarized_res$MSE)
lambda.min = summarized_res$lambda[idx]
index_1se = with(summarized_res,which(MSE < MSE[idx]+se[idx])[1])
lambda_1se = summarized_res$lambda[index_1se]
cvfit[[i]] =glmnet(X1,Y1,family = "gaussian",alpha=0, lambda = lambda.min)
}
coefficients.ridge=as.matrix(coefficients(cvfit[[1]]))
for (i in 2:n.impute){coefficients.ridge=cbind(coefficients.ridge,
as.matrix(coefficients(cvfit[[i]]))
)}
coefficients.ridge1=rowMeans(coefficients.ridge) ### coefficients for x4 and x3 are ~0
X=as.matrix(data_glmnet[,-1])
predictions.ridge[out.fold]=coefficients.ridge1[1]+X[out.fold,] %*% coefficients.ridge1[2:length(coefficients.ridge1)]
}
plot(x2.full,predictions.ridge)  ### these are the out of sample predictions
summary(lm(x2.full~predictions.ridge))
mean((x2.full-predictions.ridge)^2) ###MSE
library(glmnet)
X<-matrix(rnorm(50*200),50,200)
Y<-rbinom(50,1,0.5)
nfolds = 10
nreps = 3
res = lapply(1:nreps,function(i){
fit = cv.glmnet(x=X,y=Y,nfolds=nfolds)
data.frame(MSE_mean=fit$cvm,lambda=fit$lambda,se=fit$cvsd)
})
res = do.call(rbind,res)
library(dplyr)
summarized_res = res %>%
group_by(lambda) %>%
summarise(MSE=mean(MSE_mean),se=mean(se)) %>%
arrange(desc(lambda))
library(predcomp)
?predcompare
library(devtools) # Make sure that the devtools library is loaded
install_github("esm-ispm-unibe-ch-REPRODUCIBLE/calibration_benefit");
library(predcomp)
simbinary(100)
?predcompare
uninstall(pkg="predcomp")
library(devtools) # Make sure that the devtools library is loaded
install_github("esm-ispm-unibe-ch-REPRODUCIBLE/calibration_benefit");
library("devtools")
library("roxygen2")
setwd("C:/Users/Orestis/Google Drive/PROJECT/calibration for benefit for prediction models/R code calibration for benefit/predcomp")
setwd("C:/Users/Orestis/Google Drive/PROJECT/calibration for benefit for prediction models/calibration_benefit")
document()
load_all(".")
?predcompare
